[build-system]
requires = ["setuptools>=45", "wheel", "pip>=21.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llama-gpu"
version = "0.1.0"
description = "GPU-accelerated Llama model implementation with ROCm support"
readme = "README.md"
requires-python = ">=3.8"
license = { file = "LICENSE" }
authors = [{ name = "Kevin H", email = "kevin@example.com" }]

[tool.black]
line-length = 88
target-version = ['py38']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88

[tool.pytest.ini_options]
minversion = "6.0"
addopts = "-ra -q"
testpaths = ["tests"]

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.pylint.messages_control]
disable = ["C0111", "C0103"]
